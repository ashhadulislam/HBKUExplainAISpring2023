{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc10afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# def change_weights(X_train,y_train,X_test,y_test,weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07622faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the entropy functions work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cedc5b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0549201679861442\n"
     ]
    }
   ],
   "source": [
    "pk = np.array([1/5, 2/5, 2/5])  # fair coin\n",
    "H = entropy(pk)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b39465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0549201679861442\n"
     ]
    }
   ],
   "source": [
    "H=-0.2*(np.log(0.2))-0.4*(np.log(0.4))-0.4*(np.log(0.4))\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f37313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "def calculate_probabilities(list_labels,uniq_labels):\n",
    "    '''\n",
    "    this function calculates the probabilities of each label in the list of labels\n",
    "    it is calculated by number of labels in class A/all labels\n",
    "    number of labels in class B/all labels\n",
    "    and so on\n",
    "    '''\n",
    "    \n",
    "    # put your code here\n",
    "    #By Khatereh\n",
    "    label_counting = {label: list_labels.count(label) for label in uniq_labels}\n",
    "    total_labels = len(list_labels)\n",
    "    probabilities = [count / total_labels for count in label_counting.values()]\n",
    "    return probabilities\n",
    "    #return [1/3,1/3,1/3]\n",
    "    \n",
    "    \n",
    "    \n",
    "# test your function\n",
    "list_labels=[1,2,0,1,2,0]\n",
    "uniq_labels=[0,1,2]\n",
    "print(calculate_probabilities(list_labels,uniq_labels))\n",
    "# this should print somehting like 0.33,0.33,0.33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad5dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5219280948873621\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calc_entropy_from_probabilities(list_probas):\n",
    "    '''\n",
    "    list_probas is the list of probabiities\n",
    "    the formula for entropy is\n",
    "    sum(-proba*log(proba))\n",
    "    '''\n",
    "     # for now returning the same list\n",
    "    # put your code to calculate entropy\n",
    "    #By Khatereh\n",
    "    entropy = 0\n",
    "    for proba in list_probas:\n",
    "        if proba > 0:\n",
    "            entropy -= proba * math.log2(proba)\n",
    "    return entropy\n",
    "\n",
    "# test your function\n",
    "list_probas=[1/5, 2/5, 2/5]\n",
    "print(calc_entropy_from_probabilities(list_probas))\n",
    "# above should print 1.054..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169e9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def information_gain(old_entropy,new_entropies,count_items):\n",
    "    '''\n",
    "    from the list of new entropies, calculate the overall new entropy\n",
    "    \n",
    "    formula is something like:\n",
    "    overall_new_entropy = entropy1*proportion1 + entropy2*proportion2+ entropy3*proportion3 ...\n",
    "    \n",
    "    igain=old_entropy-overall_new_entropy\n",
    "    '''\n",
    "    #By Khatereh\n",
    "    overall_new_entropy = 0\n",
    "    total_count = sum(count_items)\n",
    "    for i, entropy in enumerate(new_entropies):\n",
    "        overall_new_entropy += entropy * count_items[i] / total_count\n",
    "    igain = old_entropy - overall_new_entropy    \n",
    "    return igain\n",
    "\n",
    "\n",
    "#test your function\n",
    "old_entropy=1\n",
    "new_entropies=[0,0.65]\n",
    "count_items=[4,6]\n",
    "print(information_gain(old_entropy,new_entropies,count_items))\n",
    "# above should print 0.61\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a4e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3120181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7e9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats=X_train.shape[1]\n",
    "def initialize_weights(number_features):\n",
    "    '''\n",
    "    the first set of weights corresponding to the features\n",
    "    defaults to 1\n",
    "    '''\n",
    "    \n",
    "    weights=np.array([2 for i in range(number_features)])\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6792d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(initialize_weights(num_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c0cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce9f4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_weights(weights):\n",
    "    new_weights=[]\n",
    "    for i in range(weights[-1].shape[0]):\n",
    "        new_weights.append(np.random.uniform(0,1))\n",
    "    return np.array(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12921475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_and_measure_accuracy(X,y,weights):    \n",
    "    res=np.sum(X*weights[-1],axis=1)\n",
    "    res = np.tanh(res)\n",
    "    res[res>0.5]=1\n",
    "    res[res<=0.5]=0\n",
    "    acc=accuracy_score(y, res)\n",
    "    return acc\n",
    "    \n",
    "def get_train_test_accuracy(X_train,y_train,X_test,y_test,weights):\n",
    "    train_acc=apply_and_measure_accuracy(X_train,y_train,weights)\n",
    "    test_acc=apply_and_measure_accuracy(X_test,y_test,weights)\n",
    "    return train_acc,test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "139b2ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(100,)\n",
      "Initial test acc [0.3]\n"
     ]
    }
   ],
   "source": [
    "wt_init=[initialize_weights(num_feats)]\n",
    "res=np.sum(X_test*wt_init[-1],axis=1)\n",
    "res = np.tanh(res)\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "print(res.shape)\n",
    "acc=accuracy_score(y_test, res)\n",
    "test_accuracies=[acc]\n",
    "\n",
    "res=np.sum(X_train*wt_init[-1],axis=1)\n",
    "res = np.tanh(res)\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "print(res.shape)\n",
    "acc=accuracy_score(y_train, res)\n",
    "\n",
    "train_accuracies=[acc]\n",
    "print(\"Initial test acc\",test_accuracies)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_weights(X_train,y_train,X_test,y_test,weights,train_accuracies,test_accuracies):\n",
    "    print(\"Trial number \",len(weights))\n",
    "    \n",
    "    train_acc,test_acc=get_train_test_accuracy(X_train,y_train,X_test,y_test,weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # store the accuracy in this list of accuracies\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(\"train\",train_acc,\"test\",test_acc)\n",
    "    print(test_accuracies[-1],test_accuracies[-2])\n",
    "    \n",
    "    # exit condition\n",
    "    if test_accuracies[-1]<test_accuracies[-2]:\n",
    "        print(\"returning\")\n",
    "        return weights,train_accuracies,test_accuracies\n",
    "    \n",
    "    # change the weights according to the accuracy\n",
    "    new_weights=change_weights(weights)\n",
    "    weights.append(new_weights)\n",
    "    return train_weights(X_train,y_train,X_test,y_test,weights,train_accuracies,test_accuracies)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f32ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0264aa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial number  1\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  2\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  3\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  4\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  5\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  6\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  7\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  8\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  9\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  10\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  11\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  12\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  13\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  14\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  15\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  16\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  17\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  18\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  19\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  20\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  21\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  22\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  23\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  24\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  25\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  26\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  27\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  28\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  29\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  30\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  31\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  32\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  33\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  34\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  35\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  36\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  37\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  38\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  39\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  40\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  41\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  42\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  43\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  44\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  45\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  46\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  47\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  48\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  49\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  50\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  51\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  52\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  53\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  54\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  55\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  56\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  57\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  58\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  59\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  60\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  61\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  62\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  63\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  64\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  65\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  66\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  67\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  68\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  69\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  70\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  71\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  72\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  73\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  74\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  75\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  76\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  77\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  78\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  79\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  80\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  81\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  82\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  83\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  84\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  85\n",
      "train 0.35 test 0.3\n",
      "0.3 0.3\n",
      "Trial number  86\n",
      "train 0.38 test 0.36\n",
      "0.36 0.3\n",
      "Trial number  87\n",
      "train 0.35 test 0.3\n",
      "0.3 0.36\n",
      "returning\n"
     ]
    }
   ],
   "source": [
    "weights,train_accuracies,test_accuracies=train_weights(X_train,y_train,X_test,y_test,wt_init,train_accuracies,test_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b82aabf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "### Test the weights in the pre-final iteration\n",
    "res=np.sum(X_test*weights[-2],axis=1)\n",
    "res = np.tanh(res)\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "acc=accuracy_score(y_test, res)\n",
    "print(acc)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b42be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
