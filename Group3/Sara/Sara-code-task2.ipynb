{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\nfrom scipy.stats import entropy\n\n# import some data to play with\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n# def change_weights(X_train,y_train,X_test,y_test,weights):","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-07T15:19:50.751937Z","iopub.execute_input":"2023-02-07T15:19:50.752355Z","iopub.status.idle":"2023-02-07T15:19:50.761237Z","shell.execute_reply.started":"2023-02-07T15:19:50.752304Z","shell.execute_reply":"2023-02-07T15:19:50.760207Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"#Check if the entropy function works\npk = np.array([1/5, 2/5, 2/5])  # fair coin\nH = entropy(pk)\nprint(H)\n#H=-0.2*(np.log(0.2))-0.4*(np.log(0.4))-0.4*(np.log(0.4))\n#print(H)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.767459Z","iopub.execute_input":"2023-02-07T15:19:50.768599Z","iopub.status.idle":"2023-02-07T15:19:50.775729Z","shell.execute_reply.started":"2023-02-07T15:19:50.768557Z","shell.execute_reply":"2023-02-07T15:19:50.774618Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"1.0549201679861442\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef calculate_probabilities(list_labels, uniq_labels):\n    '''\n    Author: Sara Nassar \n    this function calculates the probabilities of each label in the list of labels\n    it is calculated by number of labels in class A/all labels\n    number of labels in class B/all labels\n    and so on\n    '''\n        \n    # Create a dictionary to store the counts of each label\n    counts = {}\n\n    # Loop through the labels in list_labels\n    for label in list_labels:\n        # If the label is not in the dictionary, add it and set its count to 1\n        if label not in counts:\n            counts[label] = 1\n        # If the label is already in the dictionary, increment its count by 1\n        else:\n            counts[label] += 1\n    \n    # Finding the unique labels\n    uniq = np.unique(uniq_labels)\n\n    # Calculating the total number of labels\n    total = len(list_labels)\n\n    # Calculating the probabilities of each label\n    probabilities = [counts[label] / total for label in uniq]\n\n    return probabilities","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.777887Z","iopub.execute_input":"2023-02-07T15:19:50.778443Z","iopub.status.idle":"2023-02-07T15:19:50.788929Z","shell.execute_reply.started":"2023-02-07T15:19:50.778401Z","shell.execute_reply":"2023-02-07T15:19:50.787496Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# Test your function\nlist_labels=[1,2,0,1,2,0]\nuniq_labels=[0,1,2]\nprint(calculate_probabilities(list_labels,uniq_labels))","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.794253Z","iopub.execute_input":"2023-02-07T15:19:50.794918Z","iopub.status.idle":"2023-02-07T15:19:50.804120Z","shell.execute_reply.started":"2023-02-07T15:19:50.794882Z","shell.execute_reply":"2023-02-07T15:19:50.802924Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nAuthor: Sara Nassar \nlist_probas is the list of probabiities\nthe formula for entropy is\nsum(-proba*log(proba))\n'''\n#Sara Nassar - sana09516\ndef calc_entropy_from_probabilities(list_probas):\n    entropy_value = 0\n\n    for proba in list_probas:\n        # If the probability is not zero\n        if proba != 0:\n            entropy_value += -proba * np.log(proba)\n     \n    return entropy_value","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.805759Z","iopub.execute_input":"2023-02-07T15:19:50.806768Z","iopub.status.idle":"2023-02-07T15:19:50.816674Z","shell.execute_reply.started":"2023-02-07T15:19:50.806732Z","shell.execute_reply":"2023-02-07T15:19:50.815629Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"# Test your function\nlist_probbs=[1/5, 2/5, 2/5]\nprint(calc_entropy_from_probabilities(list_probbs))","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.844926Z","iopub.execute_input":"2023-02-07T15:19:50.845971Z","iopub.status.idle":"2023-02-07T15:19:50.852926Z","shell.execute_reply.started":"2023-02-07T15:19:50.845923Z","shell.execute_reply":"2023-02-07T15:19:50.852005Z"},"trusted":true},"execution_count":139,"outputs":[{"name":"stdout","text":"1.0549201679861442\n","output_type":"stream"}]},{"cell_type":"code","source":"def information_gain(old_entropy,new_entropies,count_items):\n    '''\n    Author: Sara Nassar \n    from the list of new entropies, calculate the overall new entropy\n    \n    formula is something like:\n    overall_new_entropy = entropy1*proportion1 + entropy2*proportion2+ entropy3*proportion3 ...\n    \n    igain=old_entropy-overall_new_entropy\n    '''\n    \n    overall_new_entropy = 0\n    \n    # Calculating the total number of items\n    total_items = sum(count_items)\n    \n    for i in range(len(new_entropies)):\n        # Calculating the proportion of items in the current partition\n        proportion = count_items[i] / total_items\n        \n        # Adding the entropy of the current partition weighted by its proportion to the overall new entropy\n        overall_new_entropy += new_entropies[i] * proportion\n        \n    # Calculating the information gain\n    information_gain = old_entropy - overall_new_entropy\n    \n    return information_gain","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.857746Z","iopub.execute_input":"2023-02-07T15:19:50.858438Z","iopub.status.idle":"2023-02-07T15:19:50.865460Z","shell.execute_reply.started":"2023-02-07T15:19:50.858388Z","shell.execute_reply":"2023-02-07T15:19:50.864467Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"num_feats=X_test.shape[1]\ndef initialize_weights(number_features):\n    '''\n    the first set of weights corresponding to the features\n    For now, it defaults to 2\n    '''\n    \n    weights=np.array([2 for i in range(number_features)])\n    return weights","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.867118Z","iopub.execute_input":"2023-02-07T15:19:50.867906Z","iopub.status.idle":"2023-02-07T15:19:50.879735Z","shell.execute_reply.started":"2023-02-07T15:19:50.867873Z","shell.execute_reply":"2023-02-07T15:19:50.878507Z"},"trusted":true},"execution_count":141,"outputs":[]},{"cell_type":"code","source":"print(initialize_weights(num_feats))","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.886634Z","iopub.execute_input":"2023-02-07T15:19:50.887450Z","iopub.status.idle":"2023-02-07T15:19:50.892721Z","shell.execute_reply.started":"2023-02-07T15:19:50.887417Z","shell.execute_reply":"2023-02-07T15:19:50.891667Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"[2 2 2 2]\n","output_type":"stream"}]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.895287Z","iopub.execute_input":"2023-02-07T15:19:50.896176Z","iopub.status.idle":"2023-02-07T15:19:50.905137Z","shell.execute_reply.started":"2023-02-07T15:19:50.896134Z","shell.execute_reply":"2023-02-07T15:19:50.903943Z"},"trusted":true},"execution_count":143,"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n       0, 1, 2, 2, 1, 2])"},"metadata":{}}]},{"cell_type":"code","source":"# initialization\n# Step 1: Calculate the probabilities of 0, 1 and 2 in the y_test array\n'''\nAuthor: Sara Nassar \n'''\nproba_init=calculate_probabilities(y_test,uniq_labels)#get the probabilities for y_test\nprint(\"Initial proba=\",proba_init)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.906345Z","iopub.execute_input":"2023-02-07T15:19:50.906785Z","iopub.status.idle":"2023-02-07T15:19:50.916537Z","shell.execute_reply.started":"2023-02-07T15:19:50.906753Z","shell.execute_reply":"2023-02-07T15:19:50.915356Z"},"trusted":true},"execution_count":144,"outputs":[{"name":"stdout","text":"Initial proba= [0.38, 0.3, 0.32]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Step 2: Calculate the initial entropy of y_test, using the probability values\n'''\nAuthor: Sara Nassar \n'''\n# you might have to convert the dictionary to a list\n# get only the probability values\nlist_probas=proba_init#get list from dictionary proba_init\nprint(list_probas)\n\nentropy_init=calc_entropy_from_probabilities(list_probas)# call the entropy calculation function using the list probabilities\nprint(\"Initial entropy = \",entropy_init)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.933743Z","iopub.execute_input":"2023-02-07T15:19:50.934487Z","iopub.status.idle":"2023-02-07T15:19:50.940453Z","shell.execute_reply.started":"2023-02-07T15:19:50.934452Z","shell.execute_reply":"2023-02-07T15:19:50.939651Z"},"trusted":true},"execution_count":145,"outputs":[{"name":"stdout","text":"[0.38, 0.3, 0.32]\nInitial entropy =  1.0934927418975058\n","output_type":"stream"}]},{"cell_type":"code","source":"wt_init=initialize_weights(num_feats)\n# right now the initialize_weights function only returns 2,2,2 \nprint(wt_init)\n\n# multiply the weights with each feature and calculate the sum\n#res=# use np.sum() function\n#print(res)\n\n'''\nAuthor: Sara Nassar \n'''\n\ndef calculate_sum(weights, features):\n    # Make sure the shapes of the arrays match\n    if weights.shape[0] != features.shape[1]:\n        raise ValueError(\"The number of weights must be equal to the number of columns in the features matrix.\")\n\n    # Calculate the dot product\n    total_sum = np.dot(features, weights)\n    \n    return total_sum\n\n# multiply the weights with each feature and calculate the sum\n# Call the function\nres = calculate_sum(wt_init, X_test)\n\n# Print the result\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.948451Z","iopub.execute_input":"2023-02-07T15:19:50.949008Z","iopub.status.idle":"2023-02-07T15:19:50.969295Z","shell.execute_reply.started":"2023-02-07T15:19:50.948977Z","shell.execute_reply":"2023-02-07T15:19:50.968207Z"},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"[2 2 2 2]\n[29.6 23.  39.  29.8 31.6 21.4 26.8 34.8 28.8 27.2 33.6 18.6 21.  19.2\n 21.4 31.8 35.  26.2 28.6 34.  19.4 31.6 20.8 33.8 40.2 34.4 33.6 36.4\n 19.  19.4 18.8 24.  31.2 20.  18.2 31.4 31.2 20.8 20.4 21.8 31.  31.\n 32.  22.  21.6 25.2 31.4 33.6 30.8 38.8]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n'''\nAuthor: Sara Nassar \n'''\ndef choose_threshold(features):\n    # Get the minimum and maximum values from the features matrix\n    min_value = np.min(features)\n    max_value = np.max(features)\n    \n    # Generate a random threshold between the minimum and maximum values\n    threshold = np.random.uniform(min_value, max_value)\n    \n    return threshold\n\n# Call the function\nthreshold = choose_threshold(res) \n\n# Print the result\nprint(threshold)","metadata":{"execution":{"iopub.status.busy":"2023-02-07T15:19:50.971036Z","iopub.execute_input":"2023-02-07T15:19:50.971704Z","iopub.status.idle":"2023-02-07T15:19:50.984685Z","shell.execute_reply.started":"2023-02-07T15:19:50.971670Z","shell.execute_reply":"2023-02-07T15:19:50.983645Z"},"trusted":true},"execution_count":147,"outputs":[{"name":"stdout","text":"29.566555045240882\n","output_type":"stream"}]}]}