{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\n\nfrom scipy.stats import entropy\n\n# import some data to play with\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\n# def change_weights(X_train,y_train,X_test,y_test,weights):","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-01T15:00:43.293171Z","iopub.execute_input":"2023-02-01T15:00:43.293697Z","iopub.status.idle":"2023-02-01T15:00:43.303568Z","shell.execute_reply.started":"2023-02-01T15:00:43.293661Z","shell.execute_reply":"2023-02-01T15:00:43.302405Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Check if the entropy function works\npk = np.array([1/5, 2/5, 2/5])  # fair coin\nH = entropy(pk)\nprint(H)\n#H=-0.2*(np.log(0.2))-0.4*(np.log(0.4))-0.4*(np.log(0.4))\n#print(H)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:13:47.324367Z","iopub.execute_input":"2023-02-01T15:13:47.324772Z","iopub.status.idle":"2023-02-01T15:13:47.331832Z","shell.execute_reply.started":"2023-02-01T15:13:47.324741Z","shell.execute_reply":"2023-02-01T15:13:47.330531Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"1.0549201679861442\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nthis function calculates the probabilities of each label in the list of labels\nit is calculated by number of labels in class A/all labels\nnumber of labels in class B/all labels\nand so on\n'''\n#Sara Nassar - sana09516\ndef calculate_probabilities(list_labels, uniq_labels):\n    # A dictionary to store the probabilities\n    probabilities = dict.fromkeys(uniq_labels, 0)\n    \n    # Total number of labels\n    total_labels = len(list_labels)\n    \n    for label in uniq_labels:\n        # Counting the number of times the label occurs in the list\n        count = list_labels.count(label)\n        \n        # Calculating the probability of the label\n        probability = count / total_labels\n        \n        # Storing the calculated probability in the dictionary\n        probabilities[label] = probability\n        \n    return probabilities","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:00:43.316488Z","iopub.execute_input":"2023-02-01T15:00:43.316824Z","iopub.status.idle":"2023-02-01T15:00:43.324447Z","shell.execute_reply.started":"2023-02-01T15:00:43.316793Z","shell.execute_reply":"2023-02-01T15:00:43.323364Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Test your function\nlist_labels=[1,2,0,1,2,0]\nuniq_labels=[0,1,2]\nprint(calculate_probabilities(list_labels,uniq_labels))","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:00:43.325707Z","iopub.execute_input":"2023-02-01T15:00:43.326075Z","iopub.status.idle":"2023-02-01T15:00:43.341752Z","shell.execute_reply.started":"2023-02-01T15:00:43.326044Z","shell.execute_reply":"2023-02-01T15:00:43.340742Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nlist_probas is the list of probabiities\nthe formula for entropy is\nsum(-proba*log(proba))\n'''\n#Sara Nassar - sana09516\ndef calc_entropy_from_probabilities(list_probas):\n    entropy_value = 0\n\n    for proba in list_probas:\n        # If the probability is not zero\n        if proba != 0:\n            entropy_value += -proba * np.log(proba)\n     \n    return entropy_value","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:15:14.565212Z","iopub.execute_input":"2023-02-01T15:15:14.565675Z","iopub.status.idle":"2023-02-01T15:15:14.571828Z","shell.execute_reply.started":"2023-02-01T15:15:14.565632Z","shell.execute_reply":"2023-02-01T15:15:14.570812Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Test your function\nlist_probbs=[1/5, 2/5, 2/5]\nprint(calc_entropy_from_probabilities(list_probas))","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:15:17.324515Z","iopub.execute_input":"2023-02-01T15:15:17.324925Z","iopub.status.idle":"2023-02-01T15:15:17.330939Z","shell.execute_reply.started":"2023-02-01T15:15:17.324892Z","shell.execute_reply":"2023-02-01T15:15:17.329805Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"1.0549201679861442\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nfrom the list of new entropies, calculate the overall new entropy\nformula is something like:\noverall_new_entropy = entropy1*proportion1 + entropy2*proportion2+ entropy3*proportion3 ...\nigain=old_entropy-overall_new_entropy\n'''\n#Sara Nassar - sana09516\ndef information_gain(old_entropy, new_entropies, count_items):\n    overall_new_entropy = 0\n    \n    # Calculating the total number of items\n    total_items = sum(count_items)\n    \n    for i in range(len(new_entropies)):\n        # Calculating the proportion of items in the current partition\n        proportion = count_items[i] / total_items\n        \n        # Adding the entropy of the current partition weighted by its proportion to the overall new entropy\n        overall_new_entropy += new_entropies[i] * proportion\n        \n    # Calculating the information gain\n    information_gain = old_entropy - overall_new_entropy\n    \n    return information_gain","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:21:38.721694Z","iopub.execute_input":"2023-02-01T15:21:38.722146Z","iopub.status.idle":"2023-02-01T15:21:38.729274Z","shell.execute_reply.started":"2023-02-01T15:21:38.722108Z","shell.execute_reply":"2023-02-01T15:21:38.728117Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Test your function\nold_entropy=1\nnew_entropies=[0,0.65]\ncount_items=[4,6]\nprint(information_gain(old_entropy,new_entropies,count_items))\n# above should print 0.61","metadata":{"execution":{"iopub.status.busy":"2023-02-01T15:21:41.983343Z","iopub.execute_input":"2023-02-01T15:21:41.983719Z","iopub.status.idle":"2023-02-01T15:21:41.990478Z","shell.execute_reply.started":"2023-02-01T15:21:41.983690Z","shell.execute_reply":"2023-02-01T15:21:41.989388Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"0.61\n","output_type":"stream"}]}]}