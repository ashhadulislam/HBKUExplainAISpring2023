{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "75b137d4",
      "metadata": {
        "id": "75b137d4"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from scipy.stats import entropy\n",
        "\n",
        "\n",
        "import lib as lib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ba4c42",
      "metadata": {
        "id": "04ba4c42"
      },
      "source": [
        "### Working on breast cancer data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3d91a34b",
      "metadata": {
        "id": "3d91a34b"
      },
      "outputs": [],
      "source": [
        "# import some data to play with\n",
        "#load the breast cancer dataset \n",
        "bcan = datasets.load_breast_cancer()\n",
        "X = bcan.data\n",
        "y = bcan.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "# normalize the data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d3aaecae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3aaecae",
        "outputId": "0e91de29-7973-4df1-f45c-9321c7a36119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of params 1 (weights) (100, 30)\n",
            "Shape of params 2 (thresholds) (100,)\n"
          ]
        }
      ],
      "source": [
        "# initialize params1 and params2\n",
        "\n",
        "params1=[lib.initialize_weights(X_train.shape[1]) for i in range(100)]# a vector of shape 100,4\n",
        "# call the initialize_weights function above\n",
        "\n",
        "params2=[np.random.uniform() for i in range(100)]# a vector of shape 100\n",
        "# use the np.random.uniform() function\n",
        "\n",
        "# we have a list of 100 weight vectors (params1) and 100 thresholds (params2)\n",
        "# convert them to array\n",
        "params1=np.array(params1)\n",
        "params2=np.array(params2)\n",
        "\n",
        "\n",
        "print(\"Shape of params 1 (weights)\",params1.shape)\n",
        "print(\"Shape of params 2 (thresholds)\",params2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "81b9d22c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81b9d22c",
        "outputId": "be2bc22b-a998-495f-e27a-3a0cd4509a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "param1_min [0.42060474 0.20253407 0.79809366 0.3719351  0.25834853 0.06553277\n",
            " 0.61057891 0.0365416  0.12210604 0.1125368  0.06619985 0.85793365\n",
            " 0.21534284 0.58716878 0.76528031 0.67603777 0.99827515 0.21971609\n",
            " 0.47383982 0.34549535 0.30135373 0.17451278 0.88037256 0.86634892\n",
            " 0.55425824 0.0622579  0.85016508 0.90439031 0.83388989 0.64761713] param2_min 0.662545010821571\n",
            "0.6643460978641622\n"
          ]
        }
      ],
      "source": [
        "z = lib.objective_fn_vector(params1, params2, X_train, y_train)\n",
        "# Find the global minimum\n",
        "param1_min = params1[z.argmin()] # use z.argmin()\n",
        "param2_min = params2[z.argmin()] # use z.argmin()\n",
        "\n",
        "print(\"param1_min\",param1_min,\"param2_min\",param2_min)\n",
        "print(lib.objective_fn(param1_min, param2_min, X_train, y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d82dc762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d82dc762",
        "outputId": "fb967964-1412-4788-90f7-c14fa552fff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params1 shape is  (20, 30) params2 shape is  (20,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Hyper-parameter of the algorithm\n",
        "c1 = c2 = 0.1\n",
        "w1 = np.array([np.random.uniform() for i in range(X_train.shape[1])])\n",
        "w2 = 0.8 \n",
        "# Create particles\n",
        "n_particles = 20\n",
        "np.random.seed(100)\n",
        "params1=[lib.initialize_weights(X_train.shape[1]) for i in range(n_particles)] # a vector of shape n_particles,4\n",
        "# call the initialize_weights function above\n",
        "\n",
        "params2=[np.random.uniform() for i in range(n_particles)]# a vector of shape n_particles\n",
        "# use the np.random.uniform() function\n",
        "\n",
        "params1=np.array(params1)\n",
        "params2=np.array(params2)\n",
        "\n",
        "print(\"params1 shape is \",params1.shape,\"params2 shape is \",params2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7442b873",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7442b873",
        "outputId": "d44afb1c-46be-4ea6-b8d0-446d5bd32144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pbest obj value for 20 particles are as follows [0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461\n",
            " 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461\n",
            " 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461]\n",
            "gbest obj value among all 20 particles is as follows 0.6643460978641622\n"
          ]
        }
      ],
      "source": [
        "# define velocity of each weight of every particle\n",
        "V_param1 = [lib.initialize_weights(X_train.shape[1])*0.1 for i in range(n_particles)] # shape is same as params1\n",
        "# once again can use initialize_weights function\n",
        "\n",
        "#define velocity of each threshold of every particle\n",
        "V_param2 = np.array([np.random.uniform()*0.1 for i in range(n_particles)])# shape is same as params2\n",
        "# once again use np.random.uniform() function\n",
        "\n",
        "# Initialize objective values\n",
        "pbest = (params1,params2)\n",
        "pbest_obj = lib.objective_fn_vector(params1, params2, X_train, y_train)\n",
        "gbest=(params1[pbest_obj.argmin()],params2[pbest_obj.argmin()])\n",
        "gbest_obj = pbest_obj.min()\n",
        "\n",
        "print(\"pbest obj value for 20 particles are as follows\",pbest_obj)\n",
        "print(\"gbest obj value among all 20 particles is as follows\",gbest_obj)\n",
        "# note that gbest_obj should be the minimim of all pbest_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8dd5d1ab",
      "metadata": {
        "id": "8dd5d1ab"
      },
      "outputs": [],
      "source": [
        "def update(V_param1,V_param2, params1,params2, pbest, pbest_obj, gbest, gbest_obj):\n",
        "    \"Function to do one iteration of particle swarm optimization\"\n",
        "    # these have been already initialized in the previous cells\n",
        "    \n",
        "    # Update params\n",
        "    r11,r12, r2 = np.random.rand(3)\n",
        "    V_param1=w1*V_param1+c1*r11*(pbest[0] - params1)+ c2*r2*(gbest[0]-params1)\n",
        "    V_param2=w2*V_param2+c1*r12*(pbest[1] - params2)+ c2*r2*(gbest[1]-params2)    \n",
        "#     V = w * V + c1*r11*(pbest - params1) + c2*r2*(gbest.reshape(-1,1)-X)\n",
        "    params1 = params1 + V_param1\n",
        "    params2 = params2 + V_param2\n",
        "    \n",
        "    obj = lib.objective_fn_vector(params1, params2, X_train, y_train)\n",
        "    for i in range(pbest[0].shape[0]):\n",
        "        if pbest_obj[i]>=obj[i]:\n",
        "            \n",
        "            pbest[0][i]=params1[i] # update pbest[0][i] with value of params1[i]\n",
        "            pbest[1][i]=params2[i] # update pbest[1][i] \n",
        "            pbest_obj[i]=obj[i]    # also update pbest_obj[i]\n",
        "\n",
        "            \n",
        "    gbest=(params1[pbest_obj.argmin()],params2[pbest_obj.argmin()]) # update gbest to contain the best from params1 and params 2\n",
        "    gbest_obj = pbest_obj.min() # update gbest to get the minimum of pbest_obj\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cd9d3cb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd9d3cb1",
        "outputId": "2d6d450d-d4da-4ce1-c8c9-2ddd5ef6d33b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO found best solution at f((array([3.65570865, 7.07190017, 4.05500191, 9.26377692, 0.02294058,\n",
            "       0.46981782, 2.08550332, 6.37314321, 0.67221797, 5.70213395,\n",
            "       0.8938173 , 3.40942058, 1.3159591 , 1.04214977, 8.11979007,\n",
            "       3.3337176 , 3.97242406, 0.74803574, 8.99317535, 1.32078481,\n",
            "       4.58626422, 4.65795375, 1.97023155, 3.7902729 , 0.66758815,\n",
            "       1.37132512, 3.22524034, 7.44357446, 4.24719836, 0.85780517]), 0.4098464718143954))=0.6643460978641622\n",
            "Global optimal at f([array([0.42060474, 0.20253407, 0.79809366, 0.3719351 , 0.25834853,\n",
            "       0.06553277, 0.61057891, 0.0365416 , 0.12210604, 0.1125368 ,\n",
            "       0.06619985, 0.85793365, 0.21534284, 0.58716878, 0.76528031,\n",
            "       0.67603777, 0.99827515, 0.21971609, 0.47383982, 0.34549535,\n",
            "       0.30135373, 0.17451278, 0.88037256, 0.86634892, 0.55425824,\n",
            "       0.0622579 , 0.85016508, 0.90439031, 0.83388989, 0.64761713]), 0.662545010821571])=0.6643460978641622\n"
          ]
        }
      ],
      "source": [
        "for i in range(100):\n",
        "    update(V_param1,V_param2, params1,params2, pbest, pbest_obj, gbest, gbest_obj)\n",
        "print(\"PSO found best solution at f({})={}\".format(gbest, gbest_obj))\n",
        "print(\"Global optimal at f({})={}\".format([param1_min,param2_min], lib.objective_fn(param1_min, param2_min, X_train, y_train)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3bada4ef",
      "metadata": {
        "id": "3bada4ef"
      },
      "outputs": [],
      "source": [
        "max_tree_size=128\n",
        "all_optimized_weights_list=[None for i in range(max_tree_size)]\n",
        "all_optimized_thresh_list=[None for i in range(max_tree_size)]\n",
        "all_dataset_sizes_list=[None for i in range(max_tree_size)]\n",
        "all_IG_list=[None for i in range(max_tree_size)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calc_information_gain(y,split):\n",
        "    '''\n",
        "    Calculate the information gain of a given split\n",
        "    \n",
        "    Parameters:\n",
        "        y (numpy array): The labels of the dataset\n",
        "        split (numpy array): A boolean array indicating the split\n",
        "    \n",
        "    Returns:\n",
        "        float: The information gain of the given split\n",
        "    '''\n",
        "    n=len(y)\n",
        "    n1=split.sum()\n",
        "    n2=n-n1\n",
        "    p1=n1/n\n",
        "    p2=1-p1\n",
        "    H_y=-p1*np.log2(p1+1e-10)-p2*np.log2(p2+1e-10)\n",
        "    if n1==0 or n2==0:\n",
        "        return 0\n",
        "    y1=y[split]\n",
        "    y2=y[~split]\n",
        "    H_y1 = calc_entropy(y1)\n",
        "    H_y2 = calc_entropy(y2)\n",
        "    IG = H_y - n1/n*H_y1 - n2/n*H_y2\n",
        "    return IG\n",
        "\n",
        "def calc_entropy(y):\n",
        "    '''\n",
        "    Calculate the entropy of a given dataset\n",
        "    \n",
        "    Parameters:\n",
        "        y (numpy array): The labels of the dataset\n",
        "    \n",
        "    Returns:\n",
        "        float: The entropy of the given dataset\n",
        "    '''\n",
        "    n=len(y)\n",
        "    if n==0:\n",
        "        return 0\n",
        "    p1=(y==1).sum()/n\n",
        "    p2=1-p1\n",
        "    H_y=-p1*np.log2(p1+1e-10)-p2*np.log2(p2+1e-10)\n",
        "    return H_y\n"
      ],
      "metadata": {
        "id": "TGk3xYnhdRnb"
      },
      "id": "TGk3xYnhdRnb",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "55437371",
      "metadata": {
        "id": "55437371"
      },
      "outputs": [],
      "source": [
        "def find_best_params(train_x,train_y,test_x,test_y,node_number):\n",
        "    '''\n",
        "    recursive function to get the best set of weights\n",
        "    '''\n",
        "    print(\"node_number\",node_number,\"data shape\",train_x.shape)\n",
        "    # exit condition 1: if the node_number is more than the maximum tree size, return\n",
        "    if node_number>=max_tree_size:\n",
        "        return\n",
        "    # exit condition 2: if the training dataset has one or less rows, return \n",
        "    if train_x.shape[0]<=1:\n",
        "        return \n",
        "    # exit condition 3: if the train_y has values from only one class (only 0s or only 1s and so on)\n",
        "    if len(set(train_y))==1:\n",
        "        return\n",
        "\n",
        "    # use the initialized lists as global\n",
        "    global all_optimized_weights_list\n",
        "    global all_optimized_thresh_list\n",
        "    global all_dataset_sizes_list\n",
        "    global all_IG_list\n",
        "\n",
        "    # Hyper-parameter of the algorithm\n",
        "    c1 = c2 = 0.1\n",
        "    w1 = np.array([np.random.uniform() for i in range(train_x.shape[1])])\n",
        "    w2 = 0.8 \n",
        "\n",
        "    # Create particles\n",
        "    n_particles = 20\n",
        "    np.random.seed(100)\n",
        "    params1=[lib.initialize_weights(train_x.shape[1]) for i in range(n_particles)]\n",
        "    params2=[np.random.uniform() for i in range(n_particles)]\n",
        "    params1=np.array(params1)\n",
        "    params2=np.array(params2)\n",
        "\n",
        "    # define velocity of each weight of every particle\n",
        "    V_param1 = [lib.initialize_weights(train_x.shape[1])*0.1 for i in range(n_particles)]\n",
        "\n",
        "    # define velocity of each threshold of every particle\n",
        "    V_param2 = np.array([np.random.uniform()*0.1 for i in range(n_particles)])\n",
        "\n",
        "    # Initialize objective values\n",
        "    pbest = (params1,params2)\n",
        "    pbest_obj = lib.objective_fn_vector(params1, params2, train_x, train_y)\n",
        "    gbest=(params1[pbest_obj.argmin()],params2[pbest_obj.argmin()])\n",
        "    gbest_obj = pbest_obj.min()\n",
        "\n",
        "    for i in range(100):\n",
        "        update(V_param1,V_param2, params1,params2, pbest, pbest_obj, gbest, gbest_obj)\n",
        "    \n",
        "    # add the achieved optimized values to the lists\n",
        "    all_optimized_weights_list[node_number]=gbest[0]\n",
        "    all_optimized_thresh_list[node_number]=gbest[1]\n",
        "    all_dataset_sizes_list[node_number]=train_x.shape[0]\n",
        "    all_IG_list[node_number]=calc_information_gain(train_y,train_y>=gbest[1])\n",
        "    \n",
        "    new_ys=np.dot(train_x,gbest[0])\n",
        "    \n",
        "    # normalize the new_ys\n",
        "    new_ys=(new_ys-np.min(new_ys))/(np.max(new_ys)-np.min(new_ys))\n",
        "    \n",
        "    # chop the data into two parts: left\n",
        "    train_x_left=train_x[new_ys>=gbest[1]]\n",
        "    train_y_left=train_y[new_ys>=gbest[1]]\n",
        "    left_child_node_num=node_number*2+1\n",
        "    \n",
        "    # chop the data into two parts: right\n",
        "    train_x_right=train_x[new_ys<gbest[1]]\n",
        "    train_y_right=train_y[new_ys<gbest[1]]\n",
        "    right_child_node_num=node_number*2+2\n",
        "    \n",
        "    # exit condition 4: return if information gain is 0\n",
        "    if all(ig == 0 for ig in all_IG_list):\n",
        "        return\n",
        "    \n",
        "    print(\"Left\",train_x_left.shape)\n",
        "    print(\"Right\",train_x_right.shape)\n",
        "    # make the recursion call for left\n",
        "    find_best_params(train_x_left,train_y_left,test_x,test_y,left_child_node_num)\n",
        "    # make the recursion call for right\n",
        "    find_best_params(train_x_right,train_y_right,test_x,test_y,right_child_node_num)    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b0478526",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0478526",
        "outputId": "60d060af-3fea-42c6-c625-2f1a97b6903f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node_number 0 data shape (381, 30)\n",
            "Left (93, 30)\n",
            "Right (288, 30)\n",
            "node_number 1 data shape (93, 30)\n",
            "Left (19, 30)\n",
            "Right (74, 30)\n",
            "node_number 3 data shape (19, 30)\n",
            "node_number 4 data shape (74, 30)\n",
            "Left (31, 30)\n",
            "Right (43, 30)\n",
            "node_number 9 data shape (31, 30)\n",
            "Left (9, 30)\n",
            "Right (22, 30)\n",
            "node_number 19 data shape (9, 30)\n",
            "Left (4, 30)\n",
            "Right (5, 30)\n",
            "node_number 39 data shape (4, 30)\n",
            "Left (2, 30)\n",
            "Right (2, 30)\n",
            "node_number 79 data shape (2, 30)\n",
            "Left (1, 30)\n",
            "Right (1, 30)\n",
            "node_number 159 data shape (1, 30)\n",
            "node_number 160 data shape (1, 30)\n",
            "node_number 80 data shape (2, 30)\n",
            "node_number 40 data shape (5, 30)\n",
            "node_number 20 data shape (22, 30)\n",
            "node_number 10 data shape (43, 30)\n",
            "Left (28, 30)\n",
            "Right (15, 30)\n",
            "node_number 21 data shape (28, 30)\n",
            "Left (18, 30)\n",
            "Right (10, 30)\n",
            "node_number 43 data shape (18, 30)\n",
            "Left (12, 30)\n",
            "Right (6, 30)\n",
            "node_number 87 data shape (12, 30)\n",
            "node_number 88 data shape (6, 30)\n",
            "Left (3, 30)\n",
            "Right (3, 30)\n",
            "node_number 177 data shape (3, 30)\n",
            "node_number 178 data shape (3, 30)\n",
            "node_number 44 data shape (10, 30)\n",
            "node_number 22 data shape (15, 30)\n",
            "node_number 2 data shape (288, 30)\n",
            "Left (153, 30)\n",
            "Right (135, 30)\n",
            "node_number 5 data shape (153, 30)\n",
            "Left (60, 30)\n",
            "Right (93, 30)\n",
            "node_number 11 data shape (60, 30)\n",
            "Left (33, 30)\n",
            "Right (27, 30)\n",
            "node_number 23 data shape (33, 30)\n",
            "Left (22, 30)\n",
            "Right (11, 30)\n",
            "node_number 47 data shape (22, 30)\n",
            "Left (8, 30)\n",
            "Right (14, 30)\n",
            "node_number 95 data shape (8, 30)\n",
            "Left (4, 30)\n",
            "Right (4, 30)\n",
            "node_number 191 data shape (4, 30)\n",
            "node_number 192 data shape (4, 30)\n",
            "node_number 96 data shape (14, 30)\n",
            "Left (10, 30)\n",
            "Right (4, 30)\n",
            "node_number 193 data shape (10, 30)\n",
            "node_number 194 data shape (4, 30)\n",
            "node_number 48 data shape (11, 30)\n",
            "Left (6, 30)\n",
            "Right (5, 30)\n",
            "node_number 97 data shape (6, 30)\n",
            "Left (3, 30)\n",
            "Right (3, 30)\n",
            "node_number 195 data shape (3, 30)\n",
            "node_number 196 data shape (3, 30)\n",
            "node_number 98 data shape (5, 30)\n",
            "Left (1, 30)\n",
            "Right (4, 30)\n",
            "node_number 197 data shape (1, 30)\n",
            "node_number 198 data shape (4, 30)\n",
            "node_number 24 data shape (27, 30)\n",
            "Left (20, 30)\n",
            "Right (7, 30)\n",
            "node_number 49 data shape (20, 30)\n",
            "Left (6, 30)\n",
            "Right (14, 30)\n",
            "node_number 99 data shape (6, 30)\n",
            "Left (4, 30)\n",
            "Right (2, 30)\n",
            "node_number 199 data shape (4, 30)\n",
            "node_number 200 data shape (2, 30)\n",
            "node_number 100 data shape (14, 30)\n",
            "Left (10, 30)\n",
            "Right (4, 30)\n",
            "node_number 201 data shape (10, 30)\n",
            "node_number 202 data shape (4, 30)\n",
            "node_number 50 data shape (7, 30)\n",
            "Left (3, 30)\n",
            "Right (4, 30)\n",
            "node_number 101 data shape (3, 30)\n",
            "Left (1, 30)\n",
            "Right (2, 30)\n",
            "node_number 203 data shape (1, 30)\n",
            "node_number 204 data shape (2, 30)\n",
            "node_number 102 data shape (4, 30)\n",
            "Left (1, 30)\n",
            "Right (3, 30)\n",
            "node_number 205 data shape (1, 30)\n",
            "node_number 206 data shape (3, 30)\n",
            "node_number 12 data shape (93, 30)\n",
            "Left (43, 30)\n",
            "Right (50, 30)\n",
            "node_number 25 data shape (43, 30)\n",
            "Left (27, 30)\n",
            "Right (16, 30)\n",
            "node_number 51 data shape (27, 30)\n",
            "Left (14, 30)\n",
            "Right (13, 30)\n",
            "node_number 103 data shape (14, 30)\n",
            "Left (8, 30)\n",
            "Right (6, 30)\n",
            "node_number 207 data shape (8, 30)\n",
            "node_number 208 data shape (6, 30)\n",
            "node_number 104 data shape (13, 30)\n",
            "Left (8, 30)\n",
            "Right (5, 30)\n",
            "node_number 209 data shape (8, 30)\n",
            "node_number 210 data shape (5, 30)\n",
            "node_number 52 data shape (16, 30)\n",
            "Left (9, 30)\n",
            "Right (7, 30)\n",
            "node_number 105 data shape (9, 30)\n",
            "Left (6, 30)\n",
            "Right (3, 30)\n",
            "node_number 211 data shape (6, 30)\n",
            "node_number 212 data shape (3, 30)\n",
            "node_number 106 data shape (7, 30)\n",
            "node_number 26 data shape (50, 30)\n",
            "Left (27, 30)\n",
            "Right (23, 30)\n",
            "node_number 53 data shape (27, 30)\n",
            "Left (20, 30)\n",
            "Right (7, 30)\n",
            "node_number 107 data shape (20, 30)\n",
            "Left (12, 30)\n",
            "Right (8, 30)\n",
            "node_number 215 data shape (12, 30)\n",
            "node_number 216 data shape (8, 30)\n",
            "node_number 108 data shape (7, 30)\n",
            "Left (5, 30)\n",
            "Right (2, 30)\n",
            "node_number 217 data shape (5, 30)\n",
            "node_number 218 data shape (2, 30)\n",
            "node_number 54 data shape (23, 30)\n",
            "Left (9, 30)\n",
            "Right (14, 30)\n",
            "node_number 109 data shape (9, 30)\n",
            "Left (4, 30)\n",
            "Right (5, 30)\n",
            "node_number 219 data shape (4, 30)\n",
            "node_number 220 data shape (5, 30)\n",
            "node_number 110 data shape (14, 30)\n",
            "Left (10, 30)\n",
            "Right (4, 30)\n",
            "node_number 221 data shape (10, 30)\n",
            "node_number 222 data shape (4, 30)\n",
            "node_number 6 data shape (135, 30)\n",
            "Left (109, 30)\n",
            "Right (26, 30)\n",
            "node_number 13 data shape (109, 30)\n",
            "Left (70, 30)\n",
            "Right (39, 30)\n",
            "node_number 27 data shape (70, 30)\n",
            "Left (36, 30)\n",
            "Right (34, 30)\n",
            "node_number 55 data shape (36, 30)\n",
            "node_number 56 data shape (34, 30)\n",
            "Left (21, 30)\n",
            "Right (13, 30)\n",
            "node_number 113 data shape (21, 30)\n",
            "Left (12, 30)\n",
            "Right (9, 30)\n",
            "node_number 227 data shape (12, 30)\n",
            "node_number 228 data shape (9, 30)\n",
            "node_number 114 data shape (13, 30)\n",
            "node_number 28 data shape (39, 30)\n",
            "node_number 14 data shape (26, 30)\n"
          ]
        }
      ],
      "source": [
        "node_number=0\n",
        "find_best_params(X_train,y_train,X_test,y_test,node_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ee05eb26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee05eb26",
        "outputId": "96ac9c80-ad91-4cc2-c6f3-ce440b8eca00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(381, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a756014d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a756014d",
        "outputId": "13574ec9-d4b4-425a-aa30-8b4be1569479"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " 0.4098464718143954,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "all_optimized_thresh_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cac47dbe",
      "metadata": {
        "id": "cac47dbe"
      },
      "outputs": [],
      "source": [
        "thresh=all_optimized_thresh_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bec809eb",
      "metadata": {
        "id": "bec809eb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}