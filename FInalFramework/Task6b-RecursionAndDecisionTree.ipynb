{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b137d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "import lib as lib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba4c42",
   "metadata": {},
   "source": [
    "### Working on breast cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d91a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some data to play with\n",
    "#load the breast cancer dataset \n",
    "bcan = datasets.load_breast_cancer()\n",
    "X = bcan.data\n",
    "y = bcan.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3aaecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of params 1 (weights) (100, 30)\n",
      "Shape of params 2 (thresholds) (100,)\n"
     ]
    }
   ],
   "source": [
    "# initialize params1 and params2\n",
    "\n",
    "params1=[lib.initialize_weights(X_train.shape[1]) for i in range(100)]# a vector of shape 100,4\n",
    "# call the initialize_weights function above\n",
    "\n",
    "params2=[np.random.uniform() for i in range(100)]# a vector of shape 100\n",
    "# use the np.random.uniform() function\n",
    "\n",
    "# we have a list of 100 weight vectors (params1) and 100 thresholds (params2)\n",
    "# convert them to array\n",
    "params1=np.array(params1)\n",
    "params2=np.array(params2)\n",
    "\n",
    "\n",
    "print(\"Shape of params 1 (weights)\",params1.shape)\n",
    "print(\"Shape of params 2 (thresholds)\",params2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b9d22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param1_min [5.11447013 4.53677123 0.70535817 4.43743479 1.78208326 0.28122191\n",
      " 1.41854031 4.44520929 1.20762897 2.35031583 1.76752274 2.39792243\n",
      " 1.08385403 2.33111824 2.13771321 2.99321449 6.31989251 0.82644216\n",
      " 5.41262779 0.82690422 4.08373459 4.79323638 0.89788593 6.34780814\n",
      " 5.9440157  1.3719993  2.47881292 6.31202285 4.50535511 2.38176836] param2_min 1.5023165347976417\n",
      "0.6643460978641622\n"
     ]
    }
   ],
   "source": [
    "z = lib.objective_fn_vector(params1, params2, X_train, y_train)\n",
    "# Find the global minimum\n",
    "param1_min = params1[z.argmin()] # use z.argmin()\n",
    "param2_min = params2[z.argmin()] # use z.argmin()\n",
    "\n",
    "print(\"param1_min\",param1_min,\"param2_min\",param2_min)\n",
    "print(lib.objective_fn(param1_min, param2_min, X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d82dc762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params1 shape is  (20, 30) params2 shape is  (20,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyper-parameter of the algorithm\n",
    "c1 = c2 = 0.1\n",
    "w1 = np.array([np.random.uniform() for i in range(X_train.shape[1])])\n",
    "w2 = 0.8 \n",
    "# Create particles\n",
    "n_particles = 20\n",
    "np.random.seed(100)\n",
    "params1=[lib.initialize_weights(X_train.shape[1]) for i in range(n_particles)] # a vector of shape n_particles,4\n",
    "# call the initialize_weights function above\n",
    "\n",
    "params2=[np.random.uniform() for i in range(n_particles)]# a vector of shape n_particles\n",
    "# use the np.random.uniform() function\n",
    "\n",
    "params1=np.array(params1)\n",
    "params2=np.array(params2)\n",
    "\n",
    "print(\"params1 shape is \",params1.shape,\"params2 shape is \",params2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7442b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pbest obj value for 20 particles are as follows [0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461\n",
      " 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461\n",
      " 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461 0.6643461]\n",
      "gbest obj value among all 20 particles is as follows 0.6643460978641622\n"
     ]
    }
   ],
   "source": [
    "# define velocity of each weight of every particle\n",
    "V_param1 = [lib.initialize_weights(X_train.shape[1])*0.1 for i in range(n_particles)] # shape is same as params1\n",
    "# once again can use initialize_weights function\n",
    "\n",
    "#define velocity of each threshold of every particle\n",
    "V_param2 = np.array([np.random.uniform()*0.1 for i in range(n_particles)])# shape is same as params2\n",
    "# once again use np.random.uniform() function\n",
    "\n",
    "# Initialize objective values\n",
    "pbest = (params1,params2)\n",
    "pbest_obj = lib.objective_fn_vector(params1, params2, X_train, y_train)\n",
    "gbest=(params1[pbest_obj.argmin()],params2[pbest_obj.argmin()])\n",
    "gbest_obj = pbest_obj.min()\n",
    "\n",
    "print(\"pbest obj value for 20 particles are as follows\",pbest_obj)\n",
    "print(\"gbest obj value among all 20 particles is as follows\",gbest_obj)\n",
    "# note that gbest_obj should be the minimim of all pbest_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dd5d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(V_param1,V_param2, params1,params2, pbest, pbest_obj, gbest, gbest_obj):\n",
    "    \"Function to do one iteration of particle swarm optimization\"\n",
    "    # these have been already initialized in the previous cells\n",
    "    \n",
    "    # Update params\n",
    "    r11,r12, r2 = np.random.rand(3)\n",
    "    V_param1=w1*V_param1+c1*r11*(pbest[0] - params1)+ c2*r2*(gbest[0]-params1)\n",
    "    V_param2=w2*V_param2+c1*r12*(pbest[1] - params2)+ c2*r2*(gbest[1]-params2)    \n",
    "#     V = w * V + c1*r11*(pbest - params1) + c2*r2*(gbest.reshape(-1,1)-X)\n",
    "    params1 = params1 + V_param1\n",
    "    params2 = params2 + V_param2\n",
    "    \n",
    "    obj = lib.objective_fn_vector(params1, params2, X_train, y_train)\n",
    "    for i in range(pbest[0].shape[0]):\n",
    "        if pbest_obj[i]>=obj[i]:\n",
    "            \n",
    "            pbest[0][i]=params1[i] # update pbest[0][i] with value of params1[i]\n",
    "            pbest[1][i]=params2[i] # update pbest[1][i] \n",
    "            pbest_obj[i]=obj[i]    # also update pbest_obj[i]\n",
    "\n",
    "            \n",
    "    gbest=(params1[pbest_obj.argmin()],params2[pbest_obj.argmin()]) # update gbest to contain the best from params1 and params 2\n",
    "    gbest_obj = pbest_obj.min() # update gbest to get the minimum of pbest_obj\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd9d3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSO found best solution at f((array([2.79946358, 1.41070955, 3.81947051, 2.69885723, 1.20412079,\n",
      "       0.55522579, 2.44888221, 4.44079089, 2.93263782, 2.46988633,\n",
      "       1.33231943, 0.43077251, 0.64108794, 3.57494637, 6.17952789,\n",
      "       3.71000318, 5.43441796, 1.60172093, 9.20482242, 1.4964306 ,\n",
      "       2.92058616, 1.72006017, 2.57608585, 3.68955652, 1.23193181,\n",
      "       5.48392332, 5.50967524, 4.38460724, 4.53420241, 1.52702865]), 0.4098464718143954))=0.6643460978641622\n",
      "Global optimal at f([array([5.11447013, 4.53677123, 0.70535817, 4.43743479, 1.78208326,\n",
      "       0.28122191, 1.41854031, 4.44520929, 1.20762897, 2.35031583,\n",
      "       1.76752274, 2.39792243, 1.08385403, 2.33111824, 2.13771321,\n",
      "       2.99321449, 6.31989251, 0.82644216, 5.41262779, 0.82690422,\n",
      "       4.08373459, 4.79323638, 0.89788593, 6.34780814, 5.9440157 ,\n",
      "       1.3719993 , 2.47881292, 6.31202285, 4.50535511, 2.38176836]), 1.5023165347976417])=0.6643460978641622\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    update(V_param1,V_param2, params1,params2, pbest, pbest_obj, gbest, gbest_obj)\n",
    "print(\"PSO found best solution at f({})={}\".format(gbest, gbest_obj))\n",
    "print(\"Global optimal at f({})={}\".format([param1_min,param2_min], lib.objective_fn(param1_min, param2_min, X_train, y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bada4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55437371",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tree_size=128\n",
    "all_optimized_weights_list=[None for i in range(max_tree_size)]\n",
    "all_optimized_thresh_list=[None for i in range(max_tree_size)]\n",
    "all_dataset_sizes_list=[None for i in range(max_tree_size)]\n",
    "all_IG_list=[None for i in range(max_tree_size)]\n",
    "\n",
    "\n",
    "def find_best_params(train_x,train_y,test_x,test_y,node_number):\n",
    "    '''\n",
    "    recursive function to get the best set of weights\n",
    "    '''\n",
    "    print(\"node_number\",node_number,\"data shape\",train_x.shape)\n",
    "    # exit condition 1: if the node_number is more than the maximum tree size, return\n",
    "    if node_number>=max_tree_size:\n",
    "        return\n",
    "    # exit condition 2: if the training dataset has one or less rows, return \n",
    "    if train_x.shape[0]<=1:\n",
    "        return\n",
    "    # exit condition 3: if the train_y has values from only one class (only 0s or only 1s and so on)\n",
    "    if np.unique(train_y).shape[0]==1:\n",
    "        return\n",
    "    # use the initialized lists as global\n",
    "    global all_optimized_weights_list\n",
    "    global all_optimized_thresh_list\n",
    "    global all_dataset_sizes_list\n",
    "    \n",
    "\n",
    "    # Hyper-parameter of the algorithm\n",
    "    c1 = c2 = 0.1\n",
    "    w1 = np.array([np.random.uniform() for i in range(X_train.shape[1])])\n",
    "    w2 = 0.8 \n",
    "    # Create particles\n",
    "    n_particles = 20\n",
    "    np.random.seed(100)\n",
    "    params1=[lib.initialize_weights(X_train.shape[1]) for i in range(n_particles)] # a vector of shape n_particles,n_features\n",
    "    # call the initialize_weights function above\n",
    "\n",
    "    params2=[np.random.uniform() for i in range(n_particles)]# a vector of shape n_particles\n",
    "    # use the np.random.uniform() function\n",
    "\n",
    "    params1=np.array(params1)\n",
    "    params2=np.array(params2)\n",
    "\n",
    "#     print(\"params1 shape is \",params1.shape,\"params2 shape is \",params2.shape)    \n",
    "    \n",
    "    # define velocity of each weight of every particle\n",
    "    V_param1 = [lib.initialize_weights(X_train.shape[1])*0.1 for i in range(n_particles)] # shape is same as params1\n",
    "    # once again can use initialize_weights function\n",
    "\n",
    "    #define velocity of each threshold of every particle\n",
    "    V_param2 = np.array([np.random.uniform()*0.1 for i in range(n_particles)])# shape is same as params2\n",
    "    # once again use np.random.uniform() function\n",
    "\n",
    "    # Initialize objective values\n",
    "    pbest = (params1,params2)\n",
    "    pbest_obj = lib.objective_fn_vector(params1, params2, X_train, y_train)\n",
    "    gbest=(params1[pbest_obj.argmin()],params2[pbest_obj.argmin()])\n",
    "    gbest_obj = pbest_obj.min()\n",
    "\n",
    "#     print(\"pbest obj value for 20 particles are as follows\",pbest_obj)\n",
    "#     print(\"gbest obj value among all 20 particles is as follows\",gbest_obj)   \n",
    "    \n",
    "    for i in range(100):\n",
    "        update(V_param1,V_param2, params1,params2, pbest, pbest_obj, gbest, gbest_obj)\n",
    "#     print(\"PSO found best solution at f({})={}\".format(gbest, gbest_obj))\n",
    "    \n",
    "    # add the achieved optimized values to the lists\n",
    "    all_optimized_weights_list[node_number]=gbest[0]\n",
    "    all_optimized_thresh_list[node_number]=gbest[1]\n",
    "    all_dataset_sizes_list[node_number]=train_x.shape[0]\n",
    "    all_IG_list[node_number]=gbest_obj\n",
    "#     print(\"threshold is \",gbest[1])\n",
    "#     print(\"ys are \",train_y)\n",
    "    new_ys=np.dot(train_x,gbest[0])\n",
    "    \n",
    "    new_ys=(new_ys-np.min(new_ys))/(np.max(new_ys)-np.min(new_ys))\n",
    "#     print(\"new_ys are\",new_ys)\n",
    "    \n",
    "    \n",
    "    # chop the data into two parts: left\n",
    "    train_x_left=train_x[new_ys>=gbest[1]]\n",
    "    train_y_left=train_y[new_ys>=gbest[1]]\n",
    "    left_child_node_num=node_number*2+1\n",
    "    # chop the data into two parts: right\n",
    "    train_x_right=train_x[new_ys<gbest[1]]\n",
    "    train_y_right=train_y[new_ys<gbest[1]]    \n",
    "    right_child_node_num=node_number*2+2\n",
    "    \n",
    "    # return if information gain is 0\n",
    "    if gbest_obj==0:\n",
    "        return\n",
    "    \n",
    "    print(\"Left\",train_x_left.shape)\n",
    "    print(\"Right\",train_x_right.shape)\n",
    "    # make the recursion call for left\n",
    "    find_best_params(train_x_left,train_y_left,test_x,test_y,left_child_node_num)\n",
    "    # make the recursion call for right\n",
    "    find_best_params(train_x_right,train_y_right,test_x,test_y,right_child_node_num)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b0478526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_number 0 data shape (381, 30)\n",
      "Left (101, 30)\n",
      "Right (280, 30)\n",
      "node_number 1 data shape (101, 30)\n",
      "Left (17, 30)\n",
      "Right (84, 30)\n",
      "node_number 3 data shape (17, 30)\n",
      "Left (6, 30)\n",
      "Right (11, 30)\n",
      "node_number 7 data shape (6, 30)\n",
      "node_number 8 data shape (11, 30)\n",
      "Left (4, 30)\n",
      "Right (7, 30)\n",
      "node_number 17 data shape (4, 30)\n",
      "node_number 18 data shape (7, 30)\n",
      "Left (5, 30)\n",
      "Right (2, 30)\n",
      "node_number 37 data shape (5, 30)\n",
      "Left (3, 30)\n",
      "Right (2, 30)\n",
      "node_number 75 data shape (3, 30)\n",
      "Left (2, 30)\n",
      "Right (1, 30)\n",
      "node_number 151 data shape (2, 30)\n",
      "node_number 152 data shape (1, 30)\n",
      "node_number 76 data shape (2, 30)\n",
      "node_number 38 data shape (2, 30)\n",
      "node_number 4 data shape (84, 30)\n",
      "Left (33, 30)\n",
      "Right (51, 30)\n",
      "node_number 9 data shape (33, 30)\n",
      "node_number 10 data shape (51, 30)\n",
      "Left (28, 30)\n",
      "Right (23, 30)\n",
      "node_number 21 data shape (28, 30)\n",
      "Left (16, 30)\n",
      "Right (12, 30)\n",
      "node_number 43 data shape (16, 30)\n",
      "Left (12, 30)\n",
      "Right (4, 30)\n",
      "node_number 87 data shape (12, 30)\n",
      "Left (7, 30)\n",
      "Right (5, 30)\n",
      "node_number 175 data shape (7, 30)\n",
      "node_number 176 data shape (5, 30)\n",
      "node_number 88 data shape (4, 30)\n",
      "node_number 44 data shape (12, 30)\n",
      "Left (2, 30)\n",
      "Right (10, 30)\n",
      "node_number 89 data shape (2, 30)\n",
      "node_number 90 data shape (10, 30)\n",
      "Left (4, 30)\n",
      "Right (6, 30)\n",
      "node_number 181 data shape (4, 30)\n",
      "node_number 182 data shape (6, 30)\n",
      "node_number 22 data shape (23, 30)\n",
      "Left (15, 30)\n",
      "Right (8, 30)\n",
      "node_number 45 data shape (15, 30)\n",
      "Left (8, 30)\n",
      "Right (7, 30)\n",
      "node_number 91 data shape (8, 30)\n",
      "node_number 92 data shape (7, 30)\n",
      "Left (5, 30)\n",
      "Right (2, 30)\n",
      "node_number 185 data shape (5, 30)\n",
      "node_number 186 data shape (2, 30)\n",
      "node_number 46 data shape (8, 30)\n",
      "Left (6, 30)\n",
      "Right (2, 30)\n",
      "node_number 93 data shape (6, 30)\n",
      "Left (3, 30)\n",
      "Right (3, 30)\n",
      "node_number 187 data shape (3, 30)\n",
      "node_number 188 data shape (3, 30)\n",
      "node_number 94 data shape (2, 30)\n",
      "Left (1, 30)\n",
      "Right (1, 30)\n",
      "node_number 189 data shape (1, 30)\n",
      "node_number 190 data shape (1, 30)\n",
      "node_number 2 data shape (280, 30)\n",
      "Left (151, 30)\n",
      "Right (129, 30)\n",
      "node_number 5 data shape (151, 30)\n",
      "Left (64, 30)\n",
      "Right (87, 30)\n",
      "node_number 11 data shape (64, 30)\n",
      "Left (35, 30)\n",
      "Right (29, 30)\n",
      "node_number 23 data shape (35, 30)\n",
      "Left (22, 30)\n",
      "Right (13, 30)\n",
      "node_number 47 data shape (22, 30)\n",
      "Left (12, 30)\n",
      "Right (10, 30)\n",
      "node_number 95 data shape (12, 30)\n",
      "Left (8, 30)\n",
      "Right (4, 30)\n",
      "node_number 191 data shape (8, 30)\n",
      "node_number 192 data shape (4, 30)\n",
      "node_number 96 data shape (10, 30)\n",
      "Left (6, 30)\n",
      "Right (4, 30)\n",
      "node_number 193 data shape (6, 30)\n",
      "node_number 194 data shape (4, 30)\n",
      "node_number 48 data shape (13, 30)\n",
      "Left (6, 30)\n",
      "Right (7, 30)\n",
      "node_number 97 data shape (6, 30)\n",
      "Left (3, 30)\n",
      "Right (3, 30)\n",
      "node_number 195 data shape (3, 30)\n",
      "node_number 196 data shape (3, 30)\n",
      "node_number 98 data shape (7, 30)\n",
      "Left (5, 30)\n",
      "Right (2, 30)\n",
      "node_number 197 data shape (5, 30)\n",
      "node_number 198 data shape (2, 30)\n",
      "node_number 24 data shape (29, 30)\n",
      "Left (13, 30)\n",
      "Right (16, 30)\n",
      "node_number 49 data shape (13, 30)\n",
      "Left (7, 30)\n",
      "Right (6, 30)\n",
      "node_number 99 data shape (7, 30)\n",
      "Left (5, 30)\n",
      "Right (2, 30)\n",
      "node_number 199 data shape (5, 30)\n",
      "node_number 200 data shape (2, 30)\n",
      "node_number 100 data shape (6, 30)\n",
      "node_number 50 data shape (16, 30)\n",
      "Left (8, 30)\n",
      "Right (8, 30)\n",
      "node_number 101 data shape (8, 30)\n",
      "Left (5, 30)\n",
      "Right (3, 30)\n",
      "node_number 203 data shape (5, 30)\n",
      "node_number 204 data shape (3, 30)\n",
      "node_number 102 data shape (8, 30)\n",
      "Left (5, 30)\n",
      "Right (3, 30)\n",
      "node_number 205 data shape (5, 30)\n",
      "node_number 206 data shape (3, 30)\n",
      "node_number 12 data shape (87, 30)\n",
      "Left (47, 30)\n",
      "Right (40, 30)\n",
      "node_number 25 data shape (47, 30)\n",
      "Left (24, 30)\n",
      "Right (23, 30)\n",
      "node_number 51 data shape (24, 30)\n",
      "Left (15, 30)\n",
      "Right (9, 30)\n",
      "node_number 103 data shape (15, 30)\n",
      "Left (6, 30)\n",
      "Right (9, 30)\n",
      "node_number 207 data shape (6, 30)\n",
      "node_number 208 data shape (9, 30)\n",
      "node_number 104 data shape (9, 30)\n",
      "Left (5, 30)\n",
      "Right (4, 30)\n",
      "node_number 209 data shape (5, 30)\n",
      "node_number 210 data shape (4, 30)\n",
      "node_number 52 data shape (23, 30)\n",
      "Left (11, 30)\n",
      "Right (12, 30)\n",
      "node_number 105 data shape (11, 30)\n",
      "node_number 106 data shape (12, 30)\n",
      "Left (6, 30)\n",
      "Right (6, 30)\n",
      "node_number 213 data shape (6, 30)\n",
      "node_number 214 data shape (6, 30)\n",
      "node_number 26 data shape (40, 30)\n",
      "Left (23, 30)\n",
      "Right (17, 30)\n",
      "node_number 53 data shape (23, 30)\n",
      "Left (11, 30)\n",
      "Right (12, 30)\n",
      "node_number 107 data shape (11, 30)\n",
      "node_number 108 data shape (12, 30)\n",
      "Left (6, 30)\n",
      "Right (6, 30)\n",
      "node_number 217 data shape (6, 30)\n",
      "node_number 218 data shape (6, 30)\n",
      "node_number 54 data shape (17, 30)\n",
      "node_number 6 data shape (129, 30)\n",
      "Left (110, 30)\n",
      "Right (19, 30)\n",
      "node_number 13 data shape (110, 30)\n",
      "Left (69, 30)\n",
      "Right (41, 30)\n",
      "node_number 27 data shape (69, 30)\n",
      "Left (44, 30)\n",
      "Right (25, 30)\n",
      "node_number 55 data shape (44, 30)\n",
      "Left (28, 30)\n",
      "Right (16, 30)\n",
      "node_number 111 data shape (28, 30)\n",
      "Left (14, 30)\n",
      "Right (14, 30)\n",
      "node_number 223 data shape (14, 30)\n",
      "node_number 224 data shape (14, 30)\n",
      "node_number 112 data shape (16, 30)\n",
      "node_number 56 data shape (25, 30)\n",
      "node_number 28 data shape (41, 30)\n",
      "Left (28, 30)\n",
      "Right (13, 30)\n",
      "node_number 57 data shape (28, 30)\n",
      "Left (15, 30)\n",
      "Right (13, 30)\n",
      "node_number 115 data shape (15, 30)\n",
      "Left (7, 30)\n",
      "Right (8, 30)\n",
      "node_number 231 data shape (7, 30)\n",
      "node_number 232 data shape (8, 30)\n",
      "node_number 116 data shape (13, 30)\n",
      "node_number 58 data shape (13, 30)\n",
      "node_number 14 data shape (19, 30)\n"
     ]
    }
   ],
   "source": [
    "node_number=0\n",
    "find_best_params(X_train,y_train,X_test,y_test,node_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee05eb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381, 30)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a756014d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " 0.4098464718143954,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_optimized_thresh_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cac47dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=all_optimized_thresh_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec809eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
