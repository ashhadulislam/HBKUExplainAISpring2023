{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc10afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# def change_weights(X_train,y_train,X_test,y_test,weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07622faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the entropy functions work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cedc5b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0549201679861442\n"
     ]
    }
   ],
   "source": [
    "pk = np.array([1/5, 2/5, 2/5])  # fair coin\n",
    "H = entropy(pk)\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b39465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0549201679861442\n"
     ]
    }
   ],
   "source": [
    "H=-0.2*(np.log(0.2))-0.4*(np.log(0.4))-0.4*(np.log(0.4))\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f37313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_probabilities(list_labels, uniq_labels):\n",
    "    '''\n",
    "    Author: Sara Nassar \n",
    "    this function calculates the probabilities of each label in the list of labels\n",
    "    it is calculated by number of labels in class A/all labels\n",
    "    number of labels in class B/all labels\n",
    "    and so on\n",
    "    '''\n",
    "    \n",
    "    # A dictionary to store the probabilities\n",
    "    probabilities = dict.fromkeys(uniq_labels, 0)\n",
    "    \n",
    "    # Total number of labels\n",
    "    total_labels = len(list_labels)\n",
    "    \n",
    "    for label in uniq_labels:\n",
    "        # Counting the number of times the label occurs in the list\n",
    "        count = list_labels.count(label)\n",
    "        \n",
    "        # Calculating the probability of the label\n",
    "        probability = count / total_labels\n",
    "        \n",
    "        # Storing the calculated probability in the dictionary\n",
    "        probabilities[label] = probability\n",
    "        \n",
    "    return probabilities    \n",
    "    \n",
    "    \n",
    "# test your function\n",
    "list_labels=[1,2,0,1,2,0]\n",
    "uniq_labels=[0,1,2]\n",
    "print(calculate_probabilities(list_labels,uniq_labels))\n",
    "# this should print somehting like 0.33,0.33,0.33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad5dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0549201679861442\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calc_entropy_from_probabilities(list_probas):\n",
    "    '''\n",
    "    Author: Sara Nassar \n",
    "    list_probas is the list of probabiities\n",
    "    the formula for entropy is\n",
    "    sum(-proba*log(proba))\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    entropy_value = 0\n",
    "\n",
    "    for proba in list_probas:\n",
    "        # If the probability is not zero\n",
    "        if proba != 0:\n",
    "            entropy_value += -proba * np.log(proba)\n",
    "     \n",
    "    return entropy_value\n",
    "\n",
    "\n",
    "# test your function\n",
    "list_probas=[1/5, 2/5, 2/5]\n",
    "print(calc_entropy_from_probabilities(list_probas))\n",
    "# above should print 1.054..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "169e9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n"
     ]
    }
   ],
   "source": [
    "def information_gain(old_entropy,new_entropies,count_items):\n",
    "    '''\n",
    "    Author: Sara Nassar \n",
    "    from the list of new entropies, calculate the overall new entropy\n",
    "    \n",
    "    formula is something like:\n",
    "    overall_new_entropy = entropy1*proportion1 + entropy2*proportion2+ entropy3*proportion3 ...\n",
    "    \n",
    "    igain=old_entropy-overall_new_entropy\n",
    "    '''\n",
    "    \n",
    "    overall_new_entropy = 0\n",
    "    \n",
    "    # Calculating the total number of items\n",
    "    total_items = sum(count_items)\n",
    "    \n",
    "    for i in range(len(new_entropies)):\n",
    "        # Calculating the proportion of items in the current partition\n",
    "        proportion = count_items[i] / total_items\n",
    "        \n",
    "        # Adding the entropy of the current partition weighted by its proportion to the overall new entropy\n",
    "        overall_new_entropy += new_entropies[i] * proportion\n",
    "        \n",
    "    # Calculating the information gain\n",
    "    information_gain = old_entropy - overall_new_entropy\n",
    "    \n",
    "    return information_gain\n",
    "\n",
    "#test your function\n",
    "old_entropy=1\n",
    "new_entropies=[0,0.65]\n",
    "count_items=[4,6]\n",
    "print(information_gain(old_entropy,new_entropies,count_items))\n",
    "# above should print 0.61\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a4e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3120181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7e9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats=X_train.shape[1]\n",
    "def initialize_weights(number_features):\n",
    "    '''\n",
    "    the first set of weights corresponding to the features\n",
    "    For now, it defaults to 2\n",
    "    '''\n",
    "    \n",
    "    weights=np.array([2 for i in range(number_features)])\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6792d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(initialize_weights(num_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c0cb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 2, 2, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d28fb",
   "metadata": {},
   "source": [
    "### Task 2: Perform one iteration of Information gain calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b821b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial proba= {0: 0.38, 1: 0.3, 2: 0.32}\n",
      "[0.38, 0.3, 0.32]\n",
      "Initial entropy =  1.0934927418975058\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "# Author: Bilal \n",
    "\n",
    "# step 1 calculate the probabilities of 0, 1 and 2 in the y_test array\n",
    "proba_init = calculate_probabilities(y_test.tolist(),np.unique(y_test).tolist())\n",
    "print(\"Initial proba=\",proba_init)\n",
    "\n",
    "# step 2 calculate the initial entropy of y_test, using the probability values\n",
    "# you might have to convert the dictionary to a list\n",
    "# get only the probability values\n",
    "list_probas=list(proba_init.values())\n",
    "print(list_probas)\n",
    "entropy_init=calc_entropy_from_probabilities(list_probas)\n",
    "print(\"Initial entropy = \",entropy_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38242b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2]\n",
      "[29.6 23.  39.  29.8 31.6 21.4 26.8 34.8 28.8 27.2 33.6 18.6 21.  19.2\n",
      " 21.4 31.8 35.  26.2 28.6 34.  19.4 31.6 20.8 33.8 40.2 34.4 33.6 36.4\n",
      " 19.  19.4 18.8 24.  31.2 20.  18.2 31.4 31.2 20.8 20.4 21.8 31.  31.\n",
      " 32.  22.  21.6 25.2 31.4 33.6 30.8 38.8]\n"
     ]
    }
   ],
   "source": [
    "# Author: Bilal\n",
    "\n",
    "wt_init=initialize_weights(num_feats)\n",
    "# right now the initialize_weights function only returns 2,2,2 \n",
    "print(wt_init)\n",
    "\n",
    "# multiply the weights with each feature and calculate the sum\n",
    "res=np.sum(X_test * wt_init, axis=1)\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2f0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df150dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.529687516262147\n"
     ]
    }
   ],
   "source": [
    "# Author: Bilal\n",
    "\n",
    "# choose a threshold between minimum and maximum\n",
    "threshold=np.random.uniform(res.min(), res.max())\n",
    "print(threshold)\n",
    "\n",
    "\n",
    "# make two groups\n",
    "group1=[]\n",
    "group2=[]\n",
    "\n",
    "for i in range(res.shape[0]):\n",
    "    if res[i]<threshold:\n",
    "        group1.append(y_test[i])\n",
    "    else:\n",
    "        group2.append(y_test[i])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "346e4c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG= 0.2717019705773003\n"
     ]
    }
   ],
   "source": [
    "# Author: Bilal\n",
    "proba_gr1=calculate_probabilities(group1,np.unique(group1).tolist())\n",
    "proba_gr1=list(proba_gr1.values()) \n",
    "entropy_group1=calc_entropy_from_probabilities(proba_gr1)\n",
    "count_group1=len(proba_gr1)\n",
    "\n",
    "proba_gr2=calculate_probabilities(group2,np.unique(group2).tolist())\n",
    "proba_gr2=list(proba_gr2.values()) \n",
    "entropy_group2=calc_entropy_from_probabilities(proba_gr2)\n",
    "count_group2=len(proba_gr2)\n",
    "\n",
    "new_entropies=[entropy_group1,entropy_group2]\n",
    "count_items=[count_group1,count_group2]\n",
    "ig=information_gain(entropy_init,new_entropies,count_items)\n",
    "print(\"IG=\",ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fe43d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a1a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee898c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86ca74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07278bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7f18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81bab401",
   "metadata": {},
   "source": [
    "### End of task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9f4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_weights(weights):\n",
    "    new_weights=[]\n",
    "    for i in range(weights[-1].shape[0]):\n",
    "        new_weights.append(np.random.uniform(0,1))\n",
    "    return np.array(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12921475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_and_measure_accuracy(X,y,weights):    \n",
    "    res=np.sum(X*weights[-1],axis=1)\n",
    "    res = np.tanh(res)\n",
    "    res[res>0.5]=1\n",
    "    res[res<=0.5]=0\n",
    "    acc=accuracy_score(y, res)\n",
    "    return acc\n",
    "    \n",
    "def get_train_test_accuracy(X_train,y_train,X_test,y_test,weights):\n",
    "    train_acc=apply_and_measure_accuracy(X_train,y_train,weights)\n",
    "    test_acc=apply_and_measure_accuracy(X_test,y_test,weights)\n",
    "    return train_acc,test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139b2ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "(100,)\n",
      "Initial test acc [0.3]\n"
     ]
    }
   ],
   "source": [
    "wt_init=[initialize_weights(num_feats)]\n",
    "res=np.sum(X_test*wt_init[-1],axis=1)\n",
    "res = np.tanh(res)\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "print(res.shape)\n",
    "acc=accuracy_score(y_test, res)\n",
    "test_accuracies=[acc]\n",
    "\n",
    "res=np.sum(X_train*wt_init[-1],axis=1)\n",
    "res = np.tanh(res)\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "print(res.shape)\n",
    "acc=accuracy_score(y_train, res)\n",
    "\n",
    "train_accuracies=[acc]\n",
    "print(\"Initial test acc\",test_accuracies)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_weights(X_train,y_train,X_test,y_test,weights,train_accuracies,test_accuracies):\n",
    "    print(\"Trial number \",len(weights))\n",
    "    \n",
    "    train_acc,test_acc=get_train_test_accuracy(X_train,y_train,X_test,y_test,weights)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # store the accuracy in this list of accuracies\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    print(\"train\",train_acc,\"test\",test_acc)\n",
    "    print(test_accuracies[-1],test_accuracies[-2])\n",
    "    \n",
    "    # exit condition\n",
    "    if test_accuracies[-1]<test_accuracies[-2]:\n",
    "        print(\"returning\")\n",
    "        return weights,train_accuracies,test_accuracies\n",
    "    \n",
    "    # change the weights according to the accuracy\n",
    "    new_weights=change_weights(weights)\n",
    "    weights.append(new_weights)\n",
    "    return train_weights(X_train,y_train,X_test,y_test,weights,train_accuracies,test_accuracies)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f32ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights,train_accuracies,test_accuracies=train_weights(X_train,y_train,X_test,y_test,wt_init,train_accuracies,test_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66e4778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3, 0.42, 0.3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b82aabf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "### Test the weights in the pre-final iteration\n",
    "res=np.sum(X_test*weights[-2],axis=1)\n",
    "res = np.tanh(res)\n",
    "res[res>0.5]=1\n",
    "res[res<=0.5]=0\n",
    "acc=accuracy_score(y_test, res)\n",
    "print(acc)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b42be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37kern",
   "language": "python",
   "name": "py37kern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
